{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d7fe926",
   "metadata": {},
   "source": [
    "# Baseline Solution - Monte Carlo Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcaafdf",
   "metadata": {},
   "source": [
    "## This notebook documents the baseline solution for ADC 2023. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46c438b",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Our challenge is to provide a conditional probability distribution for each target (7 in total) given an observation from the Ariel Space Telescope. \n",
    "\n",
    "Depending on the information content of the observation and the associated observation noise (which is a function of the instrument and the planetary system), the resultant error bounds on each target and their joint conditional distribution will be different.\n",
    "\n",
    "There are many directions you can take to tackle the problem on hand. We would like to get you started with our baseline solution. Inside this notebook you will find the setup for the baseline model, ways to compute the competition score and how to package the output into the competition format.\n",
    "\n",
    "Spectroscopic data alone are usually informative enough to provide a reasonable estiamte on the targets. After all, the trough and peaks in the spectra encoded information about the relative abundance of each gaseous species (see [Yip et al.](https://iopscience.iop.org/article/10.3847/1538-3881/ac1744>) ). The supplementary information also helps to better constrain some of the phyiscal quantities (see our discussion [here](https://www.ariel-datachallenge.space/ML/documentation/about) if you want to learn about the underlying physics :) , but I shall leave that to you. \n",
    "\n",
    "The baseline solution trains a CNN to output a deterministic estimate for each atmospheric target. At inference time, the network is made to produce probabilistic output by activating the dropout layers in the network (Monte Carlo Dropout, [Gal et al. 2016](https://arxiv.org/abs/1506.02142)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61537610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from helper import *\n",
    "from preprocessing import *\n",
    "from submit_format import to_competition_format\n",
    "from posterior_utils import *\n",
    "from spectral_metric import *\n",
    "from FM_utils_final import *\n",
    "import taurex.log\n",
    "taurex.log.disableLogging()\n",
    "from MCDropout import MC_Convtrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10834d90",
   "metadata": {},
   "source": [
    "### Fix seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b708058f",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RJUP = 69911000\n",
    "MJUP = 1.898e27\n",
    "RSOL = 696340000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21a8402",
   "metadata": {},
   "source": [
    "## Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = 'PATH/TO/TrainingData'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'PATH/TO/LeaderboardData/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef935b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_GT_path = os.path.join(training_path, 'Ground Truth Package')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd824849",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_training_data = h5py.File(os.path.join(training_path,'SpectralData.hdf5'),\"r\")\n",
    "aux_training_data = pd.read_csv(os.path.join(training_path,'AuxillaryTable.csv'))\n",
    "soft_label_data = pd.read_csv(os.path.join(training_GT_path, 'FM_Parameter_Table.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9b068d",
   "metadata": {},
   "source": [
    "## Extract Spectral data\n",
    "Spectral data lives in a h5py format, which is useful for navigating different cases, but their format makes it difficult to bulk manage them. The helper function helps to transform the h5py file into a matrix of size N x 52 x 4\n",
    "where N is the number of training examples, 52 is the number of wavelength channels and 4 is the observation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e90f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_matrix = to_observed_matrix(spectral_training_data,aux_training_data)\n",
    "print(\"spectral matrix shape:\", spec_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8954f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d708b807",
   "metadata": {},
   "source": [
    "# Visualising a single spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b82614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_spectrum(spectrum):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ## multiple by 100 to turn it into percentage. \n",
    "    plt.errorbar(x=spectrum[:,0], y= spectrum[:,1]*100, yerr=spectrum[:,2]*100 )\n",
    "    ## we tend to visualise it in log-scale\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Wavelength (mircon)')\n",
    "    plt.ylabel('Transit depth (%)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_spectrum(spec_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets look at another one\n",
    "visualise_spectrum(spec_matrix[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d49f8",
   "metadata": {},
   "source": [
    "it is immediately apparent that the average transit depth between two spectra can change for over an order of magnitude. The magnitude of the uncertainty can also change accordingly ( and is a function of the planetary system, brightness of the host star and instrument response function). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6386b02d",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c8aa3",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 5\n",
    "threshold = 0.8 ## for train valid split.\n",
    "N = 5000 # train on the first 5000 data instances, remember only some examples are labelled, others are unlabelled!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ae719",
   "metadata": {},
   "source": [
    "We can safely discard wlgrid (wavelength grid) and wlwidth (width of wavelength) since they are unchanged in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510cff82",
   "metadata": {},
   "source": [
    "### Extract Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99e956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract the noise\n",
    "noise = spec_matrix[:N,:,2]\n",
    "## We will incorporate the noise profile into the observed spectrum by treating the noise as Gaussian noise.\n",
    "spectra = spec_matrix[:N,:,1]\n",
    "wl_channels = len(spec_matrix[0,:,0])\n",
    "global_mean = np.mean(spectra)\n",
    "global_std = np.std(spectra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973dbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d9e0795",
   "metadata": {},
   "source": [
    "### Adding an additional feature - radius of the star \n",
    "Most of the time we know something about the planetary system before we even attempt to make an observation (we cant just point randomly with a multi-million euros instrument!). Some of these auxillary data may be useful for retrieval, here we are only using the radius of the star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890852c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add Rstar \n",
    "Rs = aux_training_data[['star_radius_m',]]\n",
    "## we would prefer to use Rsol\n",
    "Rs['star_radius'] = Rs['star_radius_m']/RSOL\n",
    "Rs = Rs.drop(['star_radius_m'],axis=1)\n",
    "Rs = Rs.iloc[:N, :]\n",
    "mean_Rs = Rs.mean()\n",
    "stdev_Rs = Rs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b5ac2",
   "metadata": {},
   "source": [
    "### Get targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749830e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = ['planet_radius','planet_temp','log_H2O','log_CO2','log_CO','log_CH4','log_NH3']\n",
    "targets = soft_label_data.iloc[:N][target_labels]\n",
    "num_targets = targets.shape[1]\n",
    "targets_mean = targets.mean()\n",
    "targets_std = targets.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe76dd",
   "metadata": {},
   "source": [
    "## Train/valid Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e265d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.rand(len(spectra)) < threshold\n",
    "training_spectra, training_Rs,training_targets, training_noise = spectra[ind],Rs[ind],targets[ind], noise[ind]\n",
    "valid_spectra, valid_Rs, valid_targets = spectra[~ind],Rs[~ind],targets[~ind]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a9501",
   "metadata": {},
   "source": [
    "## Augment the dataset with noise (create multiple instances)\n",
    "Observational noise from Ariel forms an important part of the challenge, any model must recognise that the observation are not absolute measurement and could vary (according to the uncertainty), as that will affect the uncertainty associated with our atmospheric targets. Here we try to incorporate these information by augmenting the data with the mean noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0393e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_spectra = augment_data_with_noise(training_spectra, training_noise, repeat)\n",
    "aug_Rs = np.tile(training_Rs.values,(repeat,1))\n",
    "aug_targets = np.tile(training_targets.values,(repeat,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4036a",
   "metadata": {},
   "source": [
    "### Standardise the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787437e",
   "metadata": {},
   "source": [
    "### spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## standardise the input using global mean and stdev\n",
    "std_aug_spectra = standardise(aug_spectra, global_mean, global_std)\n",
    "std_aug_spectra = std_aug_spectra.reshape(-1, wl_channels)\n",
    "std_valid_spectra = standardise(valid_spectra, global_mean, global_std)\n",
    "std_valid_spectra = std_valid_spectra.reshape(-1, wl_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76378a24",
   "metadata": {},
   "source": [
    "### radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00714009",
   "metadata": {},
   "outputs": [],
   "source": [
    "## standardise\n",
    "std_aug_Rs= standardise(aug_Rs, mean_Rs.values.reshape(1,-1), stdev_Rs.values.reshape(1,-1))\n",
    "std_valid_Rs= standardise(valid_Rs, mean_Rs, stdev_Rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f848b1",
   "metadata": {},
   "source": [
    "### target\n",
    "We are asking the model to provide estimates for 6 atmospheric targets. In this example will be performing a supervised learning task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e863c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_aug_targets = standardise(aug_targets, targets_mean.values.reshape(1,-1), targets_std.values.reshape(1,-1))\n",
    "std_valid_targets = standardise(valid_targets, targets_mean, targets_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed42bc8",
   "metadata": {},
   "source": [
    "# Setup network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e99c1",
   "metadata": {},
   "source": [
    "### hyperparameter settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "lr= 1e-3\n",
    "epochs = 30\n",
    "filters = [32,64,64]\n",
    "dropout = 0.1\n",
    "# number of examples to generate in evaluation time (5000 is max for this competition)\n",
    "N_samples = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc9c85",
   "metadata": {},
   "source": [
    "We followed [Yip et al.](https://iopscience.iop.org/article/10.3847/1538-3881/ac1744>) and adopted a simple CNN structure and loss function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MC_Convtrainer(wl_channels,num_targets,dropout,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fea61",
   "metadata": {},
   "source": [
    "### Compile model and Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ccab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile model and run\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr),\n",
    "    loss='mse',)\n",
    "model.fit([std_aug_spectra,std_aug_Rs], \n",
    "          std_aug_targets, \n",
    "          validation_data=([std_valid_spectra, std_valid_Rs],std_valid_targets),\n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          shuffle=False,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute model with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select the corresponding GT for the validation data, and in the correct order.\n",
    "index= np.arange(len(ind))\n",
    "valid_index = index[~ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = N_samples\n",
    "y_valid_distribution = np.zeros((instances, len(std_valid_spectra), num_targets ))\n",
    "for i in tqdm(range(instances)):\n",
    "    \n",
    "    y_pred_valid = model([std_valid_spectra,std_valid_Rs],training=True)\n",
    "    y_valid_distribution[i] += y_pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a14bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_distribution = y_valid_distribution.reshape(-1,num_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_valid_org = transform_and_reshape(y_valid_distribution,targets_mean, targets_std,instances,N_testdata=len(std_valid_spectra))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d144580",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1 = y_pred_valid_org\n",
    "# weight takes into account the importance of each point in the tracedata. for now we just assume them to be equally weighted\n",
    "weights1 = np.ones((tr1.shape[0],tr1.shape[1]))/np.sum(np.ones(tr1.shape[1]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b37753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46984b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_GT = h5py.File(os.path.join(training_GT_path, 'TraceData.hdf5'),\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86591747",
   "metadata": {},
   "source": [
    "## posterior scores \n",
    "This score accounts for 80% of the final score and it is based on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_scores = []\n",
    "bounds_matrix = default_prior_bounds()\n",
    "for idx, pl_idx in enumerate(valid_index):\n",
    "    tr_GT = trace_GT[f'Planet_train{pl_idx+1}']['tracedata'][()]\n",
    "    weights_GT = trace_GT[f'Planet_train{pl_idx+1}']['weights'][()]\n",
    "    ## there are cases without ground truth, we will skip over them for this baseline\n",
    "    ## but every example in leaderboard and final evaluation set will have a complementary ground truth\n",
    "    if np.isnan(tr_GT).sum() == 1:\n",
    "        continue\n",
    "    # compute posterior loss\n",
    "    score = compute_posterior_loss(tr1[idx], weights1[idx], tr_GT, weights_GT, bounds_matrix)\n",
    "    posterior_scores.append(score)\n",
    "avg_posterior_score = np.mean(posterior_scores)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d80018",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_posterior_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cbee0",
   "metadata": {},
   "source": [
    "## spectral scores \n",
    "This score accounts for 20% of the final score and it is based on a pre-selected, classified subset of the entire dataset.\n",
    "It takes a while to compute the score, even for 100 samples, so we will randomly draw 20 in this case to illustrate the idea.\n",
    "\n",
    "CAUTION: To use this metric you must have taurex and their linelists available on your local environment. For a quick tutorial please go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd09e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_examples = 10 ## number of test examples to go through\n",
    "N_samples = 10 ## number of quantiles to sample (fixed to 10 in the competition)\n",
    "q_list = np.linspace(0.01,0.99,N_samples)\n",
    "## beta - weight of the posterior loss [0,1], and the weight of spectral loss will decrease accordingly. \n",
    "beta = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path variables\n",
    "opacity_path=\"PATH/TO/xsec/\"\n",
    "CIA_path=\"PATH/TO/cia/HITRAN\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ce7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in spectral grid\n",
    "ariel_wlgrid, ariel_wlwidth, ariel_wngrid, ariel_wnwidth = ariel_resolution()\n",
    "## Initialise base T3 model for ADC2023\n",
    "fm = initialise_forward_model(opacity_path, CIA_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raed auxillary information from the input file (Provided from ADC2023)\n",
    "aux_df = aux_training_data\n",
    "# ensure the dimensionality matches forward model's input.\n",
    "Rs = aux_df['star_radius_m']/RSOL\n",
    "# Rp = aux_df['planet_radius_m']/RJUP\n",
    "Mp = aux_df['planet_mass_kg']/MJUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select few random validation data for spectral loss computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_scores = []\n",
    "bounds_matrix = default_prior_bounds()\n",
    "for idx, pl_idx in enumerate(valid_index):\n",
    "    ## put an early stop here as it will take forever to go through 5000 examples. \n",
    "    if idx == 20:\n",
    "        break\n",
    "    tr_GT = trace_GT[f'Planet_train{pl_idx+1}']['tracedata'][()]\n",
    "    weights_GT = trace_GT[f'Planet_train{pl_idx+1}']['weights'][()]\n",
    "    # again to avoid unlabelled data\n",
    "    if np.isnan(tr_GT).sum() == 1:\n",
    "        continue\n",
    "\n",
    "    proxy_compute_spectrum = setup_dedicated_fm(fm, idx, Rs, Mp, ariel_wngrid, ariel_wnwidth )\n",
    "\n",
    "    score = compute_spectral_loss(tr1[idx], weights1[idx], tr_GT,weights_GT,bounds_matrix,proxy_compute_spectrum,q_list)\n",
    "    spectral_scores.append(score)\n",
    "avg_spectral_score = np.mean(spectral_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff22765",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = (1-beta)*avg_spectral_score + beta *avg_posterior_score\n",
    "print(f\"final loss is {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4423bb",
   "metadata": {},
   "source": [
    "# Generate prediction for leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af6336",
   "metadata": {},
   "source": [
    "### load leaderboard data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8488fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_test_data = h5py.File(os.path.join(test_path,'SpectralData.hdf5'),\"r\")\n",
    "aux_test_data = pd.read_csv(os.path.join(test_path,'AuxillaryTable.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce08e4",
   "metadata": {},
   "source": [
    "### same pre-processing as before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d88ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spec_matrix = to_observed_matrix(spec_test_data,aux_test_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e932a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_test_spectra = standardise(test_spec_matrix[:,:,1], global_mean, global_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ee734",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Rs = aux_test_data[['star_radius_m']]\n",
    "## we would prefer to use RSol \n",
    "test_Rs['star_radius'] = test_Rs['star_radius_m']/RSOL\n",
    "test_Rs = test_Rs.drop(['star_radius_m'],axis=1)\n",
    "std_test_Rs= standardise(test_Rs, mean_Rs, stdev_Rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47661bea",
   "metadata": {},
   "source": [
    "## Predict and postprocess\n",
    "We will sample 5000 times by activating dropout at inference phase. This is done explicitly via training = True. Note that in the competition, any sample size bigger than 5000 will NOT be accepted. However, the sample size must have a minimum of 1000 points to be a valid submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e55168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = N_samples\n",
    "y_pred_distribution = np.zeros((instances, len(std_test_spectra), num_targets ))\n",
    "for i in tqdm(range(instances)):\n",
    "    \n",
    "    y_pred = model([std_test_spectra,std_test_Rs],training=True)\n",
    "    y_pred_distribution[i] += y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cbf4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distribution = y_pred_distribution.reshape(-1,num_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_org = transform_and_reshape(y_pred_distribution,targets_mean, targets_std,instances,N_testdata=len(std_test_spectra))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03019da",
   "metadata": {},
   "source": [
    "## Package output into desired format\n",
    "We follow specific formats in the competition, to help make the process as painless as possible, we have included a few helper functions to make sure you have the right format in place for the submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracedata = y_pred_test_org\n",
    "# weight takes into account the importance of each point in the tracedata. \n",
    "weight = np.ones((tracedata.shape[0],tracedata.shape[1]))/np.sum(np.ones(tracedata.shape[1]) )\n",
    "\n",
    "submission = to_competition_format(tracedata, \n",
    "                                        weight, \n",
    "                                        name=\"submission.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d9a33",
   "metadata": {},
   "source": [
    "## check!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec52ac61",
   "metadata": {},
   "source": [
    "## Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808d3c3",
   "metadata": {},
   "source": [
    "There are different direction to take from here on, let us summarise the shortcomings of this model:\n",
    "- The data preprocessing is quite simplistic and could have invested with more efforts.\n",
    "- we have only used 5000 data points, instead of the full dataset\n",
    "- we didnt train the model with results from the retrieval ( Tracedata.hdf5), which are the GT for this competition.\n",
    "- The conditional distribution from MCDropout is very restricted and Gaussian-like\n",
    "- So far we havent considered the atmospheric targets as a joint distribution\n",
    "- We have only used stellar radius from the auxillary information\n",
    "- We have not done any hyperparameter tuning \n",
    "- the train test split here is not clean, as in, we split the data after we have augmented the data, which results in information leakage to the validation data. There is no leakage to the test data though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112940ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
